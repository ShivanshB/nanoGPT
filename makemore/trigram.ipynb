{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "07a01552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4537c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "540d2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(''.join(words)))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad4979e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "# creating trigram dataset\n",
    "for w in words:\n",
    "    letters = ['.'] + list(w) + ['.']\n",
    "    for char1, char2, char3 in zip(letters, letters[1:], letters[2:]):      \n",
    "        xs.append([stoi[char1], stoi[char2]])\n",
    "        ys.append(stoi[char3])\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c40b99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  5],\n",
      "        [ 5, 13],\n",
      "        [13, 13],\n",
      "        [13,  1],\n",
      "        [ 0, 15],\n",
      "        [15, 12],\n",
      "        [12,  9],\n",
      "        [ 9, 22],\n",
      "        [22,  9],\n",
      "        [ 9,  1]]) tensor([13, 13,  1,  0, 12,  9, 22,  9,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "print(xs[:10], ys[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a0a72669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b5b7d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113, 54])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack vectors to get one starting layer of 54 nodes\n",
    "x_enc = F.one_hot(xs, num_classes=27).reshape(-1, 54).float()\n",
    "x_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c29fd8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_enc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70247216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e9bd2e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((54, 27), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8e7e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.130555152893066\n",
      "3.033756732940674\n",
      "2.743847370147705\n",
      "2.6067185401916504\n",
      "2.5272040367126465\n",
      "2.475642442703247\n",
      "2.4396748542785645\n",
      "2.4131760597229004\n",
      "2.392824649810791\n",
      "2.376692295074463\n",
      "2.3635809421539307\n",
      "2.3527047634124756\n",
      "2.3435280323028564\n",
      "2.3356738090515137\n",
      "2.3288698196411133\n",
      "2.32291579246521\n",
      "2.3176605701446533\n",
      "2.3129873275756836\n",
      "2.308805465698242\n",
      "2.305042266845703\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "NUM_ITERS = 200\n",
    "\n",
    "n = ys.numel()\n",
    "lr = 10\n",
    "losses = []\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    # forward pass\n",
    "    logits = x_enc @ W\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = -probs[torch.arange(ys.numel()), ys].log().mean()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    # clear gradients\n",
    "    W.grad = None\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # gradient update\n",
    "    W.data -= lr * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "326f9e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd463fead60>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the losses\n",
    "plt.plot(np.arange(NUM_ITERS), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0c83e",
   "metadata": {},
   "source": [
    "#### Notice that the losses converge to a value lower than the bigram model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac104bd3",
   "metadata": {},
   "source": [
    "### Sampling from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7aa25653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prey\n",
      "qatya\n",
      "een\n",
      "ayle\n",
      "oujto\n",
      "xengeomyo\n",
      "wbe\n",
      "vmaynna\n",
      "er\n",
      "fbe\n",
      "rion\n",
      "maynn\n",
      "paligelina\n",
      "rasstanne\n",
      "zahwa\n",
      "srhia\n",
      "areschilemarialins\n",
      "kah\n",
      "lonimarein\n",
      "gdulen\n",
      "vadariabrkzellonderayka\n",
      "tynn\n",
      "phev\n",
      "ghanac\n",
      "el\n",
      "nrelaelai\n",
      "ok\n",
      "faizarcetona\n",
      "had\n",
      "von\n",
      "tynnyegrantado\n",
      "cahlley\n",
      "narelleamela\n",
      "eiya\n",
      "nexarismidam\n",
      "wakeh\n",
      "zud\n",
      "qullen\n",
      "haulony\n",
      "kamol\n",
      "typanahamikos\n",
      "vorastmay\n",
      "cey\n",
      "bmyana\n",
      "kemgrtkaydh\n",
      "mid\n",
      "via\n",
      "kiyusta\n",
      "phaulyan\n",
      "zbef\n",
      "saudienn\n",
      "gottra\n",
      "qade\n",
      "wucuz\n",
      "wmleyss\n",
      "gayrharlee\n",
      "uilyna\n",
      "reahat\n",
      "jeliahric\n",
      "zaylealyqnayanilae\n",
      "seh\n",
      "isalavdrma\n",
      "mydis\n",
      "loa\n",
      "orivan\n",
      "bevrisamirayn\n",
      "ehyarireyann\n",
      "jayma\n",
      "viroymi\n",
      "qra\n",
      "wlenthie\n",
      "yuh\n",
      "sh\n",
      "zainee\n",
      "keyah\n",
      "gan\n",
      "erich\n",
      "wande\n",
      "qomnee\n",
      "lamkicylo\n",
      "jani\n",
      "elgnftoo\n",
      "ghoudano\n",
      "gani\n",
      "kat\n",
      "elyqbzilylariangcoriy\n",
      "kyonah\n",
      "rana\n",
      "xdusv\n",
      "fikemtenileshashartynisa\n",
      "ma\n",
      "cadenep\n",
      "syna\n",
      "ebenmathir\n",
      "danzan\n",
      "jaminorissina\n",
      "eltzusqf\n",
      "rettion\n",
      "uenn\n",
      "raya\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 100\n",
    "idx = 0\n",
    "\n",
    "p_second_letter = torch.tensor(([0] + [1] * 26))/26\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    out = ''\n",
    "    \n",
    "    state = [0, None]\n",
    "    # uniform sampling of first letter in name\n",
    "    state[1] = torch.multinomial(p_second_letter, num_samples=1, replacement=True).item()\n",
    "    state = torch.tensor(state)\n",
    "    \n",
    "    out = itos[state[0].item()] + itos[state[1].item()]\n",
    "        \n",
    "    while True:\n",
    "        x_enc_state = F.one_hot(state, num_classes=27).reshape(-1, 54).float()\n",
    "        logits = x_enc_state @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "            \n",
    "        next_char = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        \n",
    "        if next_char == 0:\n",
    "            print(out[1:])\n",
    "            break\n",
    "        \n",
    "        # updating state\n",
    "        state[0] = state[1]\n",
    "        state[1] = next_char\n",
    "        \n",
    "        out += itos[next_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e31f39f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.815441131591797\n",
      "2.6890361309051514\n",
      "2.615915298461914\n",
      "2.5670840740203857\n",
      "2.5278801918029785\n",
      "2.4942429065704346\n",
      "2.4652650356292725\n",
      "2.440870523452759\n",
      "2.4205098152160645\n",
      "2.403381586074829\n",
      "2.388702869415283\n",
      "2.375864028930664\n",
      "2.4050278663635254\n",
      "2.429809093475342\n",
      "2.4082629680633545\n",
      "2.3963258266448975\n",
      "2.3873565196990967\n",
      "2.379894733428955\n",
      "2.373426914215088\n",
      "2.3676888942718506\n",
      "2.362514019012451\n",
      "2.3577895164489746\n",
      "2.353433609008789\n",
      "2.349386692047119\n",
      "2.34560227394104\n",
      "2.342043876647949\n",
      "2.3386831283569336\n",
      "2.335496425628662\n",
      "2.3324646949768066\n",
      "2.3295726776123047\n",
      "2.3268072605133057\n",
      "2.324157953262329\n",
      "2.321615695953369\n",
      "2.3191728591918945\n",
      "2.3168230056762695\n"
     ]
    }
   ],
   "source": [
    "# try adding another hidden layer + biases\n",
    "\n",
    "W1 = torch.randn((54, 27), requires_grad=True)\n",
    "W2 = torch.randn((27, 27), requires_grad=True)\n",
    "\n",
    "b1 = torch.randn(27, requires_grad=True)\n",
    "b2 = torch.randn(27, requires_grad=True)\n",
    "\n",
    "\n",
    "# training loop\n",
    "NUM_ITERS = 350\n",
    "\n",
    "n = ys.numel()\n",
    "lr = 10\n",
    "losses = []\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    # forward pass\n",
    "    logits = (((x_enc @ W1) + b1).sigmoid() @ W2) + b2\n",
    "    \n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = -probs[torch.arange(ys.numel()), ys].log().mean()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    # clear gradients\n",
    "    W1.grad = None\n",
    "    W2.grad = None\n",
    "    b1.grad = None\n",
    "    b2.grad = None\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # gradient update\n",
    "    W1.data -= lr * W1.grad\n",
    "    W2.data -= lr * W2.grad\n",
    "    b1.data -= lr * b1.grad\n",
    "    b2.data -= lr * b2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3c7538ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hark\n",
      "o\n",
      "na\n",
      "ut\n",
      "xa\n",
      "ma\n",
      "ghuy\n",
      "sun\n",
      "ach\n",
      "pe\n",
      "ra\n",
      "bahs\n",
      "ca\n",
      "vyy\n",
      "pu\n",
      "wa\n",
      "wa\n",
      "thex\n",
      "ja\n",
      "gikotyn\n",
      "brlay\n",
      "peau\n",
      "nva\n",
      "zen\n",
      "pho\n",
      "careyns\n",
      "mami\n",
      "na\n",
      "ra\n",
      "n\n",
      "ka\n",
      "o\n",
      "ora\n",
      "jy\n",
      "nl\n",
      "za\n",
      "via\n",
      "tasya\n",
      "a\n",
      "mavcllonan\n",
      "il\n",
      "fy\n",
      "ja\n",
      "qrcera\n",
      "zyly\n",
      "krnbel\n",
      "sa\n",
      "curt\n",
      "da\n",
      "pa\n",
      "en\n",
      "uomigllaks\n",
      "pra\n",
      "ir\n",
      "qdx\n",
      "som\n",
      "sa\n",
      "wo\n",
      "sorlsis\n",
      "mhrr\n",
      "ykiyahia\n",
      "jatym\n",
      "n\n",
      "zozabs\n",
      "ul\n",
      "ven\n",
      "lun\n",
      "fero\n",
      "falon\n",
      "zo\n",
      "tone\n",
      "dan\n",
      "ria\n",
      "ers\n",
      "anva\n",
      "uu\n",
      "yea\n",
      "shn\n",
      "caki\n",
      "ncil\n",
      "en\n",
      "uafkan\n",
      "emmona\n",
      "zca\n",
      "jan\n",
      "vr\n",
      "qa\n",
      "qemdon\n",
      "qahamrbtry\n",
      "den\n",
      "ly\n",
      "briy\n",
      "qhal\n",
      "gra\n",
      "ra\n",
      "di\n",
      "ki\n",
      "juc\n",
      "janlla\n",
      "njlel\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 100\n",
    "idx = 0\n",
    "\n",
    "p_second_letter = torch.tensor(([0] + [1] * 26))/26\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    out = ''\n",
    "    \n",
    "    state = [0, None]\n",
    "    # uniform sampling of first letter in name\n",
    "    state[1] = torch.multinomial(p_second_letter, num_samples=1, replacement=True).item()\n",
    "    state = torch.tensor(state)\n",
    "    \n",
    "    out = itos[state[0].item()] + itos[state[1].item()]\n",
    "        \n",
    "    while True:\n",
    "        x_enc_state = F.one_hot(state, num_classes=27).reshape(-1, 54).float()\n",
    "        logits = (((x_enc_state @ W1) + b1).sigmoid() @ W2) + b2\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "            \n",
    "        next_char = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        \n",
    "        if next_char == 0:\n",
    "            print(out[1:])\n",
    "            break\n",
    "        \n",
    "        # updating state\n",
    "        state[0] = state[1]\n",
    "        state[1] = next_char\n",
    "        \n",
    "        out += itos[next_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55ea10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
